{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5caf7e64",
   "metadata": {},
   "source": [
    "# Lab 6 - Diffusion models\n",
    "\n",
    "Diffusion models can generate beautiful images, but they have also generated a lot of hype in the realm of generative methods in the recent two years. Today, we will learn what is under their hood and implement them.\n",
    "\n",
    "Plan for today:\n",
    "* implement a [Denoising Diffusion Model](https://arxiv.org/abs/2006.11239)\n",
    "* turn it into a [Conditional one](https://arxiv.org/abs/2207.12598)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0df719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import SGD, Adam\n",
    "from torch import nn\n",
    "import torch\n",
    "from typing import List\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms as tv\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from time import sleep\n",
    "from torchvision.models import vgg16, vgg16_bn, resnet50, resnet18\n",
    "\n",
    "from collections import Counter\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a69677",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = MNIST(root=\"data\", train=True, download=True, transform=tv.ToTensor())\n",
    "\n",
    "ds_test = MNIST(root=\"data\", train=False, download=True, transform=tv.ToTensor())\n",
    "\n",
    "batch_size=128\n",
    "dl_train = DataLoader(ds_train, batch_size, shuffle=True, drop_last=False) # dataloader with full dataset \n",
    "\n",
    "dl_test = DataLoader(ds_test, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7556a01",
   "metadata": {},
   "source": [
    "# 1 - Denoisng diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68a1517",
   "metadata": {},
   "source": [
    "\n",
    "The denoising diffusion models generate images from random noise by iteratively de-noising them. Thus, we need to train a model which can remove small portions of noise from images:\n",
    "\n",
    "![diffusion](https://cvpr2022-tutorial-diffusion-models.github.io/img/diffusion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42dcbe9",
   "metadata": {},
   "source": [
    "**Let us recap the diffusion models from the lecture:**\n",
    "\n",
    "**1.** In image $x_0$ is *diffused* by adding random noise. This process is repeated and we construct progressively more noisy images: $x_1, x_2, ..., x_T$, where $T$ is a fixed number of steps (e.g. 1000).\n",
    "\n",
    "**2.** The denoising process is designed such that after $T$ steps $x_T \\sim \\mathcal{N}(0, I)$.\n",
    "\n",
    "**3.** The diffusion process is ususally not constant across time - we define a **schedule** of $\\beta_t$, which denotes the variance of the noise sampled at each step. Ususally, $\\beta_t$ increases with $t$.\n",
    "\n",
    "**4.** The value of each $x_t$ depends solely in $x_{t-1}$ and the noise sampled at step $t$. $x_t$ is sampled from conditional distribution: $$x_t \\sim \\mathcal{N}(\\sqrt{1 - \\beta_t}x_{t-1}, \\beta_t I)$$\n",
    "\n",
    "Thus: $$x_t = \\sqrt{\\alpha_t} x_{t-1} + \\sqrt{1 - \\alpha_t} \\epsilon_{t-1} $$\n",
    "\n",
    "Where $\\alpha_t = 1 - \\beta_t$ and $\\epsilon_t \\sim \\mathcal{N}(0, I)$ is the noise sampled during step $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a84df",
   "metadata": {},
   "source": [
    "### Task 1 - implement naive noising process:\n",
    "For an image batch, please sample the noise $t$ times and return noised image. Visualize the noised images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059fbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_noise(x, t, b0=1e-4, bT=0.02, T=1000):\n",
    "    \"\"\"\n",
    "    Iterative image noising\n",
    "    x: images batch (B, C, H, W)\n",
    "    t: timesteps (B) - note that t can be different for each imagei n the batch!\n",
    "    b0, bT, T: schedule parameters - b increases uniformly between b0 and bT between steps 0 and T (maximal step).\n",
    "    \n",
    "    Returns:\n",
    "        A tensor of the same shape as x, appropriately noised\n",
    "    \"\"\"\n",
    "    return x\n",
    "    \n",
    "\n",
    "for X, _ in dl_train:\n",
    "    break\n",
    "    \n",
    "X = X[:5]\n",
    "X_noised = {t: naive_noise(X, t) for t in [0, 250, 500, 1000]}\n",
    "\n",
    "fig, ax = plt.subplots(ncols=len(X), nrows=len(X_noised), figsize=(len(X),len(X_noised)+1 ))\n",
    "\n",
    "for i, (t, Xs) in enumerate(X_noised.items()):\n",
    "    for j, x in enumerate(Xs):\n",
    "        ax[i,j].imshow(F.to_pil_image(x))\n",
    "        ax[i,j].axis(\"off\")\n",
    "        ax[i,j].set_title(f\"{t=}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06729bd",
   "metadata": {},
   "source": [
    "\n",
    "**5.** Do we need to perform sampling $t$ times to obtain $x_t$? We can do it more effectively:\n",
    "\n",
    "We can calculate the parameters of distribution $p(x_t | x_0)$: $$x_t \\sim \\mathcal{N}(\\sqrt{\\bar{\\alpha}_t}x_0, (1 - \\bar{\\alpha}_t)I)$$\n",
    "\n",
    "And sample from this distribution with a single noise sample $\\epsilon$: \n",
    "\n",
    "$$x_t =  \\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon$$\n",
    "\n",
    "Where $\\bar{\\alpha}_t = \\prod^t_{i=1} \\alpha_i$ (cumulative product)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8fd1c7",
   "metadata": {},
   "source": [
    "### Task 2 - implement an efficient sampling function\n",
    "\n",
    "For an image batch, sample a noised version at step $t$ from distribution described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_noise(x, t, b0=1e-4, bT=0.02, T=1000):\n",
    "    \"\"\"\n",
    "    x: images batch (B, C, H, W)\n",
    "    t: timesteps (B)\n",
    "    b0, bT, T: schedule parameters - b increases uniformly between b0 and bT between steps 0 and T (maximal step).\n",
    "    \n",
    "    Returns:\n",
    "        * A tensor of the same shape as x, appropriately noised\n",
    "        * epsilon - noise tensor of the same shape as x\n",
    "\n",
    "    \"\"\"\n",
    "    epsilon = ...\n",
    "    return x, epsilon\n",
    "    \n",
    "    \n",
    "X_noised = {\n",
    "    t: single_noise(X, t)[0] # we do not care about epsilon yet \n",
    "    for t in [0, 250, 500, 1000]\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(ncols=len(X), nrows=len(X_noised), figsize=(len(X),len(X_noised)+1 ))\n",
    "\n",
    "for i, (t, Xs) in enumerate(X_noised.items()):\n",
    "    for j, x in enumerate(Xs):\n",
    "        ax[i,j].imshow(F.to_pil_image(x))\n",
    "        ax[i,j].axis(\"off\")\n",
    "        ax[i,j].set_title(f\"{t=}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b291ab",
   "metadata": {},
   "source": [
    "**6.** Our model, $\\epsilon_\\theta$ must predict the parameters of distribution: $p(x_{t-1} | x_t) = \\mathcal{N}(\\mu_\\theta(x_t,t), \\Sigma_\\theta(x_t,t))$\n",
    "\n",
    "For simplicity, let variance be non-trainable: $ \\Sigma_\\theta(x_t,t) = \\beta_t I$. Thus, our model must only predict the means of the distribution. \n",
    "\n",
    "Let's simplify things even more - if our model can correctly predict the **noise** used to construct $x_t$, then we can calculate $\\mu_\\theta(x_t,t)$ from it:\n",
    "\n",
    "$$\\mu_\\theta(x_t,t)  = \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\epsilon_\\theta(x_t,t)) $$\n",
    "\n",
    "**7.** Thus, the loss function will be given by: $$\\mathcal{L}(x_0, t, \\epsilon)  = || \\epsilon - \\epsilon_\\theta(x_t, t)||$$\n",
    "\n",
    "Where $x_t =  \\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon$\n",
    "\n",
    "**8.** To sum it up, our model needs to predict the noise value $\\epsilon$ based on an image $x_t$. From that, we can calculate the mean of distribution (variance is constant for a given $t$) and sample $x_{t-1} \\sim \\mathcal{N}(\\mu_\\theta(x_t,t), \\beta_t I)$. It we do it $t$ times, we should arrive at a **denoised** image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059a8870",
   "metadata": {},
   "source": [
    "### What kind of model do we need?\n",
    "\n",
    "For the model to predict noise of the data, it needs to be $\\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ - same dimensionality of input and output. In practice, a [U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)-like architecture works well:\n",
    "\n",
    "<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" width=500></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921661e",
   "metadata": {},
   "source": [
    "### Task 3 - implement a U-Net-like net for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b8188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # initialize 2-3 downsampling / upsampling blocks\n",
    "    \n",
    "    def forward(self, X):\n",
    "        ...\n",
    "        # forward X through downsampling / upsampling. \n",
    "        # skip connections are not 100% necessary for MNIST\n",
    "        # in the DDPM paper they also use t as positional encoding, but we can also omit it for MNIST\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f6983a",
   "metadata": {},
   "source": [
    "### Task 4 - train a diffusion model\n",
    "* complete the training loop\n",
    "* every 10 epochs please visualize the sampling process on a couple of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = MNISTUNet(...)\n",
    "optim = torch.optim.Adam(diffusion.parameters(), lr=2e-4)\n",
    "\n",
    "\n",
    "def train_ddpm(\n",
    "    model, optimizer, \n",
    "    num_epochs=100,\n",
    "    b0=1e-4, bT=0.02, T=1000,\n",
    "    \n",
    "):\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        for X, _ in dl_train:\n",
    "            X = X.to(device)\n",
    "            \n",
    "            t = ... # sample timestep (t) tensors - ints between 0 and T\n",
    "            \n",
    "            X_noise, epsilon = single_noise(X, t, b0=b0, bT=bT, T=T)\n",
    "            \n",
    "            # predict the noise with model\n",
    "            # calculate the loss (MSE between true and predicted noise)\n",
    "            # optimize the model\n",
    "        \n",
    "        # evaluation - let's visualize how our model diffuses images\n",
    "        if e % 10 == 0:\n",
    "            n_images = 5\n",
    "            timesteps=[1000, 500, 250, 0]\n",
    "            \n",
    "            fig, ax = plt.subplots(\n",
    "                ncols=len(n_images), nrows=len(timesteps), \n",
    "                figsize=(len(X),len(timesteps)+1)\n",
    "            )\n",
    "            current_row = 0\n",
    "\n",
    "            X = ... # sample 5 noise vectors\n",
    "            \n",
    "            for t in range(T, -1, -1):\n",
    "                pred_noise = model(X)\n",
    "                pred_mean = ... # calculate the distribution image\n",
    "                variance = b0 + ((bT- b0) * (t/T))\n",
    "                X = ... # sample new X from distribution parameters\n",
    "                if t not in timesteps:\n",
    "                    continue\n",
    "                i = timesteps.index(t)\n",
    "                for j, x in enumerate(X):\n",
    "                    ax[i, j].imshow(F.to_pil_image(x))\n",
    "                    ax[i, j].axis(\"off\")\n",
    "                    ax[i, j].set_title(f\"{t=}\")\n",
    "                    \n",
    "            plt.suptitle(f\"{e=}\")\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be47f6d",
   "metadata": {},
   "source": [
    "# 2 - Conditional denoising diffusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a9a220",
   "metadata": {},
   "source": [
    "How to convert an uncoditional diffusion model into a [conditional one](https://arxiv.org/pdf/2207.12598.pdf)? It can be done similarly to the way we did it in the last labs in cGAN - by injecting a class vector into the latent. In practice, we can: \n",
    "* transform the class label of a sample into a one-hot vector\n",
    "* process it with a small linear network into a latent $g$\n",
    "* concatenate $g$ to a hidden representation of our U-Net\n",
    "    * for example to the bottom-most one; concatenating to multiple hidden representations can work even better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0f7acb",
   "metadata": {},
   "source": [
    "### Task 5 - modify your UNet architecture to include class conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b2e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMNISTUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # initialize 2-3 downsampling / upsampling blocks\n",
    "    \n",
    "    def forward(self, X, y):\n",
    "        ...\n",
    "        # forward X through downsampling / upsampling. \n",
    "        # transform label y into one-hot, process it with a linear layer and add to the hidden representation of X, e.g. between up/down-sampling\n",
    "        # skip connections are not 100% necessary for MNIST\n",
    "        # in the DDPM paper they also use t as positional encoding, but we can also omit it for MNIST\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0e3b0",
   "metadata": {},
   "source": [
    "In order to make our model work, we need a couple more tricks that work in practice:\n",
    "\n",
    "* **Guided / unguided training** - we want our model to be able to estimate *unconditional* diffusion (same as the previous DDPM). This can be done by conditioning it with a vector of zeros instead of one-hots. In practice, we will zero-out a portion of our one-hots with probablility $p$.\n",
    "\n",
    "* **Sampling through a combination of conditional / unconditional models** - when sampling from model $\\epsilon_\\theta$, we will repict the noise $\\epsilon$ through a linear combination of conditional and unconditional model: $$\\epsilon = (1 + w)\\epsilon_\\theta(x_t, c) - w\\epsilon_\\theta(x_t, \\emptyset)$$ where $w$ is a sampling hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b57d30",
   "metadata": {},
   "source": [
    "### Task 6 - train a conditional diffusion model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a25f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = CMNISTUNet(...)\n",
    "optim = torch.optim.Adam(diffusion.parameters(), lr=2e-4)\n",
    "\n",
    "\n",
    "def train_cddpm(\n",
    "    model, optimizer, \n",
    "    num_epochs=100,\n",
    "    num_classes=10,\n",
    "    unconditional_prob=0.1,\n",
    "    ws = [0.0, 0.5, 1.0, 2.0],\n",
    "    b0=1e-4, bT=0.02, T=1000,\n",
    "    \n",
    "):\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        for X, y in dl_train:\n",
    "            X = X.to(device)\n",
    "            y = nn.functional.one_hot(y, num_classes=num_classes).float().to(device)\n",
    "            \n",
    "            y = ... # zero-out some elements of y with probability `unconditional_prob` - those will be the unconditional samples\n",
    "            \n",
    "            t = ... # sample timestep (t) tensors - ints between 0 and T\n",
    "            \n",
    "            X_noise, epsilon = single_noise(X, t, b0=b0, bT=bT, T=T)\n",
    "            \n",
    "            # predict the noise with model\n",
    "            # calculate the loss (MSE between true and predicted noise)\n",
    "            # optimize the model\n",
    "        \n",
    "        # evaluation - let's visualize how our model diffuses images with different ws\n",
    "        if e % 20 == 0:\n",
    "            n_images = 5\n",
    "            timesteps=[1000, 500, 250, 0]\n",
    "            \n",
    "            for w in ws:\n",
    "                fig, ax = plt.subplots(\n",
    "                    ncols=len(n_images), nrows=len(timesteps), \n",
    "                    figsize=(len(X),len(timesteps)+1)\n",
    "                )\n",
    "                current_row = 0\n",
    "\n",
    "                X = ... # sample 10 noise vectors - each for one class label\n",
    "                y =  nn.functional.one_hot(\n",
    "                    torch.tensor(list(range(10))),\n",
    "                    num_classes=num_classes\n",
    "                ).float().to(device)\n",
    "\n",
    "                y_uncond = torch.zeros((10,10)).float().to(device)\n",
    "\n",
    "                for t in range(T, -1, -1):\n",
    "                    pred_noise = (1+w)*model(X, y) - w*model(X,y_uncond)\n",
    "                    pred_mean = ... # calculate the distribution image\n",
    "                    variance = b0 + ((bT- b0) * (t/T))\n",
    "                    X = ... # sample new X from distribution parameters\n",
    "                    if t not in timesteps:\n",
    "                        continue\n",
    "                    i = timesteps.index(t)\n",
    "                    for j, x in enumerate(X):\n",
    "                        ax[i, j].imshow(F.to_pil_image(x))\n",
    "                        ax[i, j].axis(\"off\")\n",
    "                        ax[i, j].set_title(f\"{t=}\")\n",
    "\n",
    "                plt.suptitle(f\"{e=}, {w=}\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cfda25",
   "metadata": {},
   "source": [
    "### Question - how does the value of $w$ influence the model's predictions?\n",
    "Hint - to answer this, you may want to sample a batch of a few examples of the same class with different $w$'s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e8b4ee",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Apart from papers, this notebook was based on the following repositories:\n",
    "* https://github.com/cloneofsimo/minDiffusion\n",
    "* https://github.com/TeaPearce/Conditional_Diffusion_MNIST\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uj",
   "language": "python",
   "name": "uj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
